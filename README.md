# 🧠 Yohan Lee (요한)
### AI Research Engineer @ KakaoBank | Building Reasoning Systems at Human & Model Scale

> _Designing language models that think, remember, and reason — like humans, but at scale._

---

## 🧩 About Me

I’m an **AI Research Engineer at KakaoBank**, focusing on **post-training and optimization of large language models** that power real-world services for **26M+ active users**.  
My work explores how **reasoning, memory, and alignment** can be reimagined to make LLMs both *cognitively inspired* and *production-ready*.

Rather than scaling parameters alone, I study how models can **think more like humans** —  
reasoning in parallel, integrating contextual memory, and aligning with human trust and intention.

---

## 🔭 Research Focus

### 🧠 Human-like Reasoning
Current LLMs reason **sequentially**, generating one token at a time.  
Inspired by recent directions such as *Soft Token Reasoning* ([arXiv:2509.19170](https://arxiv.org/abs/2509.19170)),  
I’m exploring ways to enable **parallel and continuous inference** —  
models that can revise, aggregate, and evolve thoughts before producing answers.  
This connects symbolic reasoning with diffusion-like latent dynamics, aiming for *human-parallel cognition*.

### ⚙️ Scalable Reasoning Systems
At KakaoBank, I lead **post-training and inference optimization** for **200B+ parameter LLMs**,  
building high-impact reasoning agents in financial and service domains.  
My work centers on:
- **Interleaved reasoning** combining function calls, memory, and tool use  
- **Multi-instruction reasoning**, enabling one instruction to branch into multiple sub-tasks  
- **Latency-optimized alignment**, balancing inference speed with reasoning depth  

### 🧬 Memory & Cognitive Modeling
Following earlier work on **episodic and structured memory (PREMem, 2025)**,  
I study how models can construct and manage internal memory representations —  
learning to **consolidate**, **forget**, and **contextualize** experiences across sessions.  
The goal is a reasoning loop that grounds decisions in structured, evolving memory.

### 🛡️ Trustworthy & Human-Aligned AI
Reasoning and memory must ultimately be *safe*.  
I develop and evaluate methods that ensure **consistency, transparency, and calibration** in model outputs —  
AI systems that *reflect before responding* and can *justify their reasoning processes*.  
This connects deeply to my broader pursuit: **aligning artificial reasoning with human cognition and ethics**.

---

## 🏆 Publications

- **Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval**  
  *EMNLP 2025 (Industry Track)* — The first benchmark for conversational retrieval, exposing model weaknesses.  
  _Yohan Lee, Yongwoo Song, Sangyeop Kim†_

- **PREMem: Pre-Storage Reasoning for Episodic Memory**  
  *EMNLP 2025 (Findings)* — Shifting reasoning to memory construction for personalized dialogue.  
  _Sangyeop Kim*, Yohan Lee*, Sanghwa Kim, Hyunjong Kim, Sungzoon Cho†_

- **What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs**  
  *ACL 2025 (Main)* — Revealing that context length, not shot count, drives long-context vulnerabilities.  
  _Sangyeop Kim*, Yohan Lee*, Yongwoo Song*, Kimin Lee†_

- **HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for Training-free Retrieval of Conversational Data using LLMs**  
  *NAACL 2025 (Findings)* — Training-free retrieval via hierarchical semantic indexing.  
  _Sangyeop Kim†, Hangyeul Lee, Yohan Lee_

- **SAFARI: Sample-specific Assessment Framework for AI in Real-world Interactions**  
  *NAACL 2025 (Findings)* — Automated multilingual evaluation framework for LLMs using real-world conversational data.  
  _Yohan Lee*, Sungho Park*, Sangwoo Han*, Yunsung Lee*†, Yongwoo Song, Adam Lee, Jiwung Hyun, Jaemin Kim, HyeJin Gong_

---

## 📫 Connect

📍 Seoul, South Korea  
🌐 [Portfolio](https://l-yohai.github.io/portfolio/)  
💼 [LinkedIn](https://www.linkedin.com/in/l-yohai/)  
📧 yhlee.nlp [at] gmail.com  

---

> _“AI should not only scale in size, but in understanding —  
reasoning with reflection, memory, and humanity.”_
