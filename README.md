# ğŸ§  Yohan Lee (ìš”í•œ)
### AI Research Engineer @ KakaoBank | Building Reasoning Systems at Human & Model Scale

---

## ğŸ§© About Me

Iâ€™m an **AI Research Engineer at KakaoBank**, focusing on **post-training and optimization of large language models** that power real-world services for **26M+ active users**.  
My work explores how **reasoning, memory, and alignment** can be reimagined to make LLMs both *cognitively inspired* and *production-ready*.

Rather than scaling parameters alone, I study how models can **think more like humans** â€”  reasoning in parallel, integrating contextual memory, and aligning with human trust and intention.

---

## ğŸ”­ Research Focus

### ğŸ§  Human-like Reasoning
Current LLMs reason **sequentially**, generating one token at a time.  \
Inspired by recent directions such as *Soft Token Reasoning* ([arXiv:2509.19170](https://arxiv.org/abs/2509.19170)), Iâ€™m exploring ways to enable **parallel and continuous inference** â€” models that can revise, aggregate, and evolve thoughts before producing answers.  \
This connects symbolic reasoning with diffusion-like latent dynamics, aiming for *human-parallel cognition*.

### âš™ï¸ Scalable Reasoning Systems
At KakaoBank, I lead **post-training and inference optimization** for **200B+ parameter LLMs**, building high-impact reasoning agents in financial and service domains.  

My work centers on:
- **Interleaved reasoning** combining function calls, memory, and tool use  
- **Multi-instruction reasoning**, enabling one instruction to branch into multiple sub-tasks  
- **Latency-optimized alignment**, balancing inference speed with reasoning depth  

### ğŸ§¬ Memory & Cognitive Modeling
Following earlier work on **episodic and structured memory (PREMem, 2025)**, I study how models can construct and manage internal memory representations â€” learning to **consolidate**, **forget**, and **contextualize** experiences across sessions. \
The goal is a reasoning loop that grounds decisions in structured, evolving memory.

### ğŸ›¡ï¸ Trustworthy & Human-Aligned AI
Reasoning and memory must ultimately be *safe*.  
I develop and evaluate methods that ensure **consistency, transparency, and calibration** in model outputs â€” AI systems that *reflect before responding* and can *justify their reasoning processes*. \
This connects deeply to my broader pursuit: **aligning artificial reasoning with human cognition and ethics**.

---

## ğŸ† Publications

- **Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval** (*EMNLP 2025 Industry*) \
  <a href="https://arxiv.org/abs/2510.02938"><img src="https://img.shields.io/badge/arXiv-2510.02938-b31b1b.svg" height="18"></a> \
  _**Yohan Lee**, Yongwoo Song, Sangyeop Kimâ€ _

- **Pre-Storage Reasoning for Episodic Memory: Shifting Inference Burden to Memory for Personalized Dialogue** (*EMNLP 2025*) \
  <a href="https://arxiv.org/abs/2509.10852"><img src="https://img.shields.io/badge/arXiv-2509.10852-b31b1b.svg" height="18"></a> \
  _Sangyeop Kim*, **Yohan Lee***, Sanghwa Kim, Hyunjong Kim, Sungzoon Choâ€ _

- **What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs** (*ACL 2025*) \
  <a href="https://arxiv.org/abs/2505.19773"><img src="https://img.shields.io/badge/arXiv-2505.19773-b31b1b.svg" height="18"></a> \
  _Sangyeop Kim*, **Yohan Lee***, Yongwoo Song*, Kimin Leeâ€ _

- **HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for Training-free Retrieval of Conversational Data using LLMs** (*NAACL 2025*) \
  <a href="https://arxiv.org/abs/2503.04141"><img src="https://img.shields.io/badge/arXiv-2503.04141-b31b1b.svg" height="18"></a> \
  _Sangyeop Kimâ€ , Hangyeul Lee, **Yohan Lee**_

- **SAFARI: Sample-specific Assessment Framework for AI in Real-world Interactions** (*NAACL 2025*) \
  _**Yohan Lee***, Sungho Park*, Sangwoo Han*, Yunsung Lee*â€ , Yongwoo Song, Adam Lee, Jiwung Hyun, Jaemin Kim, HyeJin Gong_

---

## ğŸ“« Connect

ğŸ“ Seoul, South Korea  
ğŸŒ [Portfolio](https://l-yohai.github.io/portfolio/)  
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/l-yohai/)  
ğŸ“§ yhlee.nlp [at] gmail.com  

---
