# üß† Yohan Lee (ÏöîÌïú)
### AI Research Engineer @ KakaoBank | Building Reasoning Systems at Human & Model Scale

> _Designing language models that think, remember, and reason ‚Äî like humans, but at scale._

---

## üß© About Me

I‚Äôm an **AI Research Engineer at KakaoBank**, focusing on **post-training and optimization of large language models** that power real-world services for **26M+ active users**.  
My work explores how **reasoning, memory, and alignment** can be reimagined to make LLMs both *cognitively inspired* and *production-ready*.

Rather than scaling parameters alone, I study how models can **think more like humans** ‚Äî  
reasoning in parallel, integrating contextual memory, and aligning with human trust and intention.

---

## üî≠ Research Focus

### üß† Human-like Reasoning
Current LLMs reason **sequentially**, generating one token at a time.  
Inspired by recent directions such as *Soft Token Reasoning* ([arXiv:2509.19170](https://arxiv.org/abs/2509.19170)),  
I‚Äôm exploring ways to enable **parallel and continuous inference** ‚Äî  
models that can revise, aggregate, and evolve thoughts before producing answers.  
This connects symbolic reasoning with diffusion-like latent dynamics, aiming for *human-parallel cognition*.

### ‚öôÔ∏è Scalable Reasoning Systems
At KakaoBank, I lead **post-training and inference optimization** for **200B+ parameter LLMs**,  
building high-impact reasoning agents in financial and service domains.  
My work centers on:
- **Interleaved reasoning** combining function calls, memory, and tool use  
- **Multi-instruction reasoning**, enabling one instruction to branch into multiple sub-tasks  
- **Latency-optimized alignment**, balancing inference speed with reasoning depth  

### üß¨ Memory & Cognitive Modeling
Following earlier work on **episodic and structured memory (PREMem, 2025)**,  
I study how models can construct and manage internal memory representations ‚Äî  
learning to **consolidate**, **forget**, and **contextualize** experiences across sessions.  
The goal is a reasoning loop that grounds decisions in structured, evolving memory.

### üõ°Ô∏è Trustworthy & Human-Aligned AI
Reasoning and memory must ultimately be *safe*.  
I develop and evaluate methods that ensure **consistency, transparency, and calibration** in model outputs ‚Äî  
AI systems that *reflect before responding* and can *justify their reasoning processes*.  
This connects deeply to my broader pursuit: **aligning artificial reasoning with human cognition and ethics**.

---

## üèÜ Publications

- **Finding Diamonds in Conversation Haystacks: A Benchmark for Conversational Data Retrieval** (*EMNLP 2025 Industry*) \
  _**Yohan Lee**, Yongwoo Song, Sangyeop Kim‚Ä†_

- **PREMem: Pre-Storage Reasoning for Episodic Memory** (*EMNLP 2025*) \
  <a href="https://arxiv.org/abs/2509.10852"><img src="https://img.shields.io/badge/arXiv-2509.10852-b31b1b.svg" height="18"></a> \
  _Sangyeop Kim*, **Yohan Lee***, Sanghwa Kim, Hyunjong Kim, Sungzoon Cho‚Ä†_

- **What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs** (*ACL 2025*) \
  <a href="https://arxiv.org/abs/2505.19773"><img src="https://img.shields.io/badge/arXiv-2505.19773-b31b1b.svg" height="18"></a> \
  _Sangyeop Kim*, **Yohan Lee***, Yongwoo Song*, Kimin Lee‚Ä†_

- **HEISIR: Hierarchical Expansion of Inverted Semantic Indexing for Training-free Retrieval of Conversational Data using LLMs** (*NAACL 2025*) \
  <a href="https://arxiv.org/abs/2503.04141"><img src="https://img.shields.io/badge/arXiv-2503.04141-b31b1b.svg" height="18"></a> \
  _Sangyeop Kim‚Ä†, Hangyeul Lee, **Yohan Lee**_

- **SAFARI: Sample-specific Assessment Framework for AI in Real-world Interactions** (*NAACL 2025*) \
  _**Yohan Lee***, Sungho Park*, Sangwoo Han*, Yunsung Lee*‚Ä†, Yongwoo Song, Adam Lee, Jiwung Hyun, Jaemin Kim, HyeJin Gong_

---

## üì´ Connect

üìç Seoul, South Korea  
üåê [Portfolio](https://l-yohai.github.io/portfolio/)  
üíº [LinkedIn](https://www.linkedin.com/in/l-yohai/)  
üìß yhlee.nlp [at] gmail.com  

---

> _‚ÄúAI should not only scale in size, but in understanding ‚Äî  
reasoning with reflection, memory, and humanity.‚Äù_
